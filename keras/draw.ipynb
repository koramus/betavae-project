{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fitted-retail",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import keras.backend as K\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os.path\n",
    "import csv\n",
    "from keras.preprocessing.image import DirectoryIterator, ImageDataGenerator\n",
    "\n",
    "dataset = 'faces' # one of 'faces' 'chairs' 'celeba'\n",
    "z_dims = 32\n",
    "beta = 0.1\n",
    "\n",
    "if dataset == 'faces':\n",
    "    channels = 1\n",
    "    likelihood = 'bernoulli'\n",
    "elif dataset == 'chairs':\n",
    "    channels = 1\n",
    "    likelihood = 'bernoulli'\n",
    "elif dataset == 'celeba':\n",
    "    channels = 3\n",
    "    likelihood = 'gaussian'\n",
    "\n",
    "grayscale = dataset == 'faces' or dataset == 'chairs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "endangered-senator",
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset == 'faces':\n",
    "    data = np.load('faces-labelled.npz')['images']\n",
    "elif dataset == 'chairs':\n",
    "    data = np.load('{}.npy'.format(dataset))\n",
    "elif dataset == 'celeba':\n",
    "    dir_iter = DirectoryIterator(\n",
    "        directory='/tmp/tmp',\n",
    "        image_data_generator=ImageDataGenerator(\n",
    "            #validation_split=\n",
    "            rescale=1/255,\n",
    "        ),\n",
    "        target_size=(64, 64),\n",
    "        color_mode='rgb', # grayscale\n",
    "        class_mode='input',\n",
    "        batch_size=1,\n",
    "        shuffle=False,\n",
    "        #seed= for shuffling\n",
    "        #subset='training'\n",
    "        interpolation='bilinear',\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "considered-upset",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NormalSampler(keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(NormalSampler, self).__init__()\n",
    "\n",
    "    def call(self, mu_logvar):\n",
    "        mu, logvar = mu_logvar\n",
    "        epsilon = K.random_normal(shape=K.shape(mu))\n",
    "        std = K.exp(logvar / 2)\n",
    "        return mu + epsilon*std\n",
    "\n",
    "\n",
    "inputs = keras.Input(shape=(channels, 64, 64))\n",
    "\n",
    "# encoder\n",
    "x = keras.layers.Conv2D(filters=32, kernel_size=4, strides=2, padding='same', activation='relu')(inputs)\n",
    "x = keras.layers.Conv2D(filters=32, kernel_size=4, strides=2, padding='same', activation='relu')(x)\n",
    "x = keras.layers.Conv2D(filters=64, kernel_size=4, strides=2, padding='same', activation='relu')(x)\n",
    "x = keras.layers.Conv2D(filters=64, kernel_size=4, strides=2, padding='same', activation='relu')(x)\n",
    "x = keras.layers.Flatten()(x)\n",
    "x = keras.layers.Dense(units=256, activation='relu')(x)\n",
    "mu = keras.layers.Dense(units=z_dims, activation=None)(x)\n",
    "logvar = keras.layers.Dense(units=z_dims, activation=None)(x)\n",
    "z = NormalSampler()([mu, logvar])\n",
    "\n",
    "encoder_mu = keras.Model(inputs=inputs, outputs=mu, name='encoder_mu')\n",
    "encoder = keras.Model(inputs=inputs, outputs=[z, mu, logvar], name='encoder')\n",
    "\n",
    "\n",
    "# decoder\n",
    "d_inputs = keras.Input(shape=(z_dims,))\n",
    "x = keras.layers.Dense(units=256, activation='relu')(d_inputs)\n",
    "x = keras.layers.Dense(units=64*4*4, activation='relu')(x)\n",
    "x = keras.layers.Reshape((64, 4, 4))(x)\n",
    "x = keras.layers.Conv2DTranspose(filters=64, kernel_size=4, strides=2, padding='same', activation='relu')(x)\n",
    "x = keras.layers.Conv2DTranspose(filters=32, kernel_size=4, strides=2, padding='same', activation='relu')(x)\n",
    "x = keras.layers.Conv2DTranspose(filters=32, kernel_size=4, strides=2, padding='same', activation='relu')(x)\n",
    "x = keras.layers.Conv2DTranspose(filters=channels, kernel_size=4, strides=2, padding='same', activation=None)(x)\n",
    "decoder = keras.Model(inputs=d_inputs, outputs=x, name='decoder')\n",
    "\n",
    "\n",
    "# combined\n",
    "outputs = decoder(encoder(inputs)[0])\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "\n",
    "model_path = os.path.join('checkpoints', '{}-{}-{}'.format(dataset, z_dims, beta))\n",
    "log_path = os.path.join('checkpoints', '{}-{}-{}.csv'.format(dataset, z_dims, beta))\n",
    "if os.path.exists(model_path):\n",
    "    model.load_weights(model_path)\n",
    "    print('Loaded existing checkpoint')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "owned-disney",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# draw full traversal of all 32 latents\n",
    "\n",
    "#i = 30100 # faces\n",
    "#i = 15000 # faces\n",
    "i = 37000 # faces\n",
    "#i = 500 # chairs\n",
    "#i = 70 # chairs\n",
    "\n",
    "if dataset == 'chairs' or dataset == 'faces':\n",
    "    test = data[i:i+1]\n",
    "elif dataset == 'celeba':\n",
    "    test = dir_iter[i][0]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "if grayscale:\n",
    "    test2 = 1/(1+np.exp(-test))\n",
    "    ax.imshow(np.reshape(test2, (64, 64)), cmap='gray')\n",
    "else:\n",
    "    test2 = test.reshape(3, 64, 64)\n",
    "    test2 = np.transpose(test2, (1, 2, 0))\n",
    "    ax.imshow(test2)\n",
    "\n",
    "    \n",
    "z = encoder_mu.predict(test)\n",
    "\n",
    "z_indices = range(32)\n",
    "n = len(z_indices)\n",
    "\n",
    "#z_range = [-1, -0.5, 0, 0.5, 1]\n",
    "z_range = [-3, -2, -1, 0, 1, 2, 3]\n",
    "m = len(z_range)\n",
    "\n",
    "fig, axs = plt.subplots(n, m, figsize=(2*m,2*n))\n",
    "fig.subplots_adjust(wspace=0, hspace=0)\n",
    "\n",
    "for i, z_i in enumerate(z_indices):\n",
    "    z_copy = np.copy(z)\n",
    "    for j, v in enumerate(z_range):\n",
    "        z_copy[0,z_i] = v\n",
    "        recon = decoder.predict(z_copy)\n",
    "        \n",
    "        recon = 1/(1+np.exp(-recon))\n",
    "        if grayscale:\n",
    "            axs[i, j].imshow(np.reshape(recon, (64, 64)), cmap='gray', aspect='auto')\n",
    "        else:\n",
    "            recon = recon.reshape(3, 64, 64)\n",
    "            recon = np.transpose(recon, (1, 2, 0))\n",
    "            axs[i, j].imshow(recon)\n",
    "        axs[i, j].set_axis_off()\n",
    "        #axs[i, j].set_title(str(i))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "established-project",
   "metadata": {},
   "outputs": [],
   "source": [
    "# traversal of a single latent over various images\n",
    "\n",
    "#images = [130, 500, 66, 3000] # chairs\n",
    "images = [3000, 37000, 40100, 55000, 70000] # faces\n",
    "n = len(images)\n",
    "\n",
    "z_i = 21\n",
    "\n",
    "#z_range = [-1, -0.5, 0, 0.5, 1]\n",
    "z_range = [-3, -1.5, 0, 1.5, 3]\n",
    "m = len(z_range)\n",
    "\n",
    "fig, axs = plt.subplots(n, m, figsize=(2*m,2*n))\n",
    "fig.subplots_adjust(wspace=0, hspace=0)\n",
    "\n",
    "for i, image_i in enumerate(images):\n",
    "    test = data[image_i:image_i+1]\n",
    "    z = encoder_mu.predict(test)\n",
    "    z_copy = np.copy(z)\n",
    "    for j, v in enumerate(z_range):\n",
    "        z_copy[0,z_i] = v\n",
    "        recon = decoder.predict(z_copy)\n",
    "        recon = 1/(1+np.exp(-recon))\n",
    "        \n",
    "        axs[i, j].imshow(np.reshape(recon, (64, 64)), cmap='gray', aspect='auto')\n",
    "        axs[i, j].set_axis_off()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
